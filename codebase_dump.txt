===================================================
FILE: LLMCat.sh
===================================================
#!/bin/bash
# Script to cat out a specified subdirectory (or the whole repo) with filename headers
# Uses git commands, explicit ignore patterns, and user-defined excludes.

# --- Configuration ---
OUTPUT_FILE="codebase_dump.txt"
TARGET_DIR_ARG="" # Store the original target directory argument if provided
EXCLUDE_PATTERNS=() # Array to store user exclusion patterns
APPEND_MODE=false # Flag for append mode
MAX_DEPTH=-1
# --- Argument Parsing ---
# Need to handle both a potential directory argument and multiple flags
POSITIONAL_ARGS=()
while [[ $# -gt 0 ]]; do
  case $1 in
    -e|--exclude)
      if [ -z "$2" ]; then
        echo "Error: $1 option requires an argument." >&2
        exit 1
      fi
      EXCLUDE_PATTERNS+=("$2")
      shift # past argument
      shift # past value
      ;;
    -a|--append)
      APPEND_MODE=true
      shift # past argument
      ;;
    -d|--depth)
      if [ -z "$2" ]; then
        echo "Error: $1 option requires a non-negative integer argument." >&2
        exit 1
      fi
      # Validate depth is a non-negative integer
      if ! [[ "$2" =~ ^[0-9]+$ ]]; then
         echo "Error: Depth value must be a non-negative integer, got '$2'." >&2
         exit 1
      fi
      MAX_DEPTH="$2"
      shift # past argument
      shift # past value
      ;;
    -h|--help)
      echo "Usage: $0 [subdirectory_path] [-a] [-e pattern_to_exclude ...]" # Modified Usage
      echo ""
      echo "Dumps specified files from a Git repository to '$OUTPUT_FILE'."
      echo ""
      echo "Arguments:"
      echo "  subdirectory_path   Optional. Path relative to the repo root to process."
      echo "                      If omitted, the entire repository is processed."
      echo ""
      echo "Options:"
      echo "  -a, --append            Append to the output file instead of overwriting it." # Added Option
      echo "  -e, --exclude PATTERN   Specify a pattern to exclude. Can be used multiple"
      echo "  -d, --depth DEPTH       Limit processing to files at most DEPTH levels deep" # Added Option
      echo "                          times. Uses Bash globbing against paths relative"
      echo "                          to the repository root (e.g., 'dist/*', '*.log',"
      echo "                          '**/__pycache__/*')."
      echo "  -h, --help              Show this help message."
      exit 0
      ;;
    -*)
      echo "Error: Unknown option: $1" >&2
      echo "Use -h or --help for usage information."
      exit 1
      ;;
    *)
      POSITIONAL_ARGS+=("$1") # save potential directory argument
      shift # past argument
      ;;
  esac
done

# Restore positional arguments (we expect 0 or 1)
set -- "${POSITIONAL_ARGS[@]}"

if [ "$#" -gt 1 ]; then
  echo "Usage: $0 [subdirectory_path] [-a] [-e pattern_to_exclude ...]" # Modified Usage
  echo "Error: Too many positional arguments (expected 0 or 1 directory path)."
  >&2
  exit 1
fi

if [ "$#" -eq 1 ]; then
  TARGET_DIR_ARG="$1"
fi

# --- Pre-checks ---

# Make sure we're in a git repository
if ! git rev-parse --is-inside-work-tree > /dev/null 2>&1; then
  echo "Error: Not in a git repository" >&2
  exit 1
fi

# Get Git repository root
GIT_ROOT=$(git rev-parse --show-toplevel)
if [ -z "$GIT_ROOT" ]; then
    echo "Error: Could not determine Git repository root." >&2
    exit 1
fi
# echo "DEBUG: Git repository root: $GIT_ROOT" >&2

# === CHANGE DIRECTORY TO REPO ROOT ===
ORIGINAL_PWD=$(pwd)
cd "$GIT_ROOT" || { echo "Error: Could not change directory to $GIT_ROOT" >&2; exit 1; }
# echo "DEBUG: Changed directory to $GIT_ROOT" >&2

# Determine target directory relative to root
if [ -z "$TARGET_DIR_ARG" ]; then
  TARGET_DIR="." # Default to current directory (which is now root)
else
  TARGET_DIR="$TARGET_DIR_ARG"
  # Remove leading/trailing slashes for consistency, handle edge cases
  TARGET_DIR="$(echo "$TARGET_DIR" | sed 's:/*$::' | sed 's:^/*::')"
  if [ "$TARGET_DIR" == "" ] || [ "$TARGET_DIR" == "." ]; then
      TARGET_DIR="." # Reset to root if only slashes were given
  fi
fi
# echo "DEBUG: Target directory specified (relative to root): '$TARGET_DIR'" >&2


# Check if the target directory exists and is a directory (relative to current dir, which is root)
if [ ! -d "$TARGET_DIR" ]; then
   echo "Error: Target path '$TARGET_DIR' (relative to $GIT_ROOT) is not a valid directory." >&2
   # Change back before exiting
   cd "$ORIGINAL_PWD" || exit 1
   exit 1
fi

# Define the path to use with git ls-files
# If TARGET_DIR is '.', git ls-files treats it like no path (list all)
# Let's pass '.' explicitly if it's the root, otherwise pass the specific subdirectory.
if [ "$TARGET_DIR" == "." ]; then
    TARGET_DIR_FOR_GIT="." # Use '.' to represent the whole repo
    TARGET_DIR_DISPLAY_NAME="repository root"
else
    TARGET_DIR_FOR_GIT="$TARGET_DIR"
    TARGET_DIR_DISPLAY_NAME="'$TARGET_DIR'"
fi
# echo "DEBUG: Path being passed to git ls-files: '$TARGET_DIR_FOR_GIT'" >&2

# Define output file path relative to where the script *was called*
OUTPUT_FILE_ABS="$ORIGINAL_PWD/$OUTPUT_FILE"
echo "Output will be saved to: $OUTPUT_FILE_ABS"

# Clear the output file or prepare for append
if $APPEND_MODE; then
  echo "Appending to existing file: $OUTPUT_FILE_ABS"
  # Optionally add a separator if appending
  if [ -s "$OUTPUT_FILE_ABS" ]; then # Check if file exists and has size > 0
      echo -e "\n\n# === Appending run: $(date) ===\n\n" >> "$OUTPUT_FILE_ABS"
  fi
else
  echo "Overwriting existing file: $OUTPUT_FILE_ABS"
  > "$OUTPUT_FILE_ABS" # Clear the output file
fi

# --- Depth Calculation Function ---
calculate_depth() {
    local file_path="$1"
    local target_dir="$2"
    local path_for_depth_calc=""

    if [[ "$target_dir" == "." ]]; then
        # Depth is relative to repo root
        path_for_depth_calc="$file_path"
    else
        # Depth is relative to the target subdirectory
        local prefix="${target_dir}/"
        # Ensure the file path starts with the target directory prefix
        if [[ "$file_path" == "$prefix"* ]]; then
            path_for_depth_calc="${file_path#$prefix}"
        elif [[ "$file_path" == "$target_dir" ]]; then
            # This case is unlikely for files listed by ls-files with a dir target
            # but conceptually a file exactly matching the target path is at depth 0
            echo 0
            return
        else
             # Should not happen with `git ls-files -- "$TARGET_DIR_FOR_GIT"`
             # If it does, treat as very deep to likely exclude? Or relative to root?
             # Let's calculate based on file_path itself, may indicate an issue.
             echo "Warning: File '$file_path' didn't match target prefix '$prefix'" >&2
             path_for_depth_calc="$file_path" # Fallback
        fi
    fi

    # If path_for_depth_calc is empty, it means the file is directly in the target dir (depth 0)
    if [[ -z "$path_for_depth_calc" ]]; then
        echo 0
        return
    fi

    # Count the number of slashes in the relative path
    # Using Bash parameter expansion for efficiency: ${var//pattern/replacement}
    local temp="${path_for_depth_calc//[^\/]/}" # Remove all non-slash characters
    local depth="${#temp}"                      # The length of the remaining string is the slash count
    echo "$depth"
}


# --- Ignore Logic Function ---
# Takes path relative to repo root (which git ls-files provides)
# --- Ignore Logic Function ---
# Takes path relative to repo root (which git ls-files provides)
should_ignore() {
  local path="$1"

  # --- Check User Excludes First ---
  for pattern in "${EXCLUDE_PATTERNS[@]}"; do
    # Use Bash Extended Globbing or Globstar if needed
    # shopt -s extglob  # Example: For !(pattern)
    # shopt -s globstar # Example: For **/some_dir/*

    # 1. Check if the path matches the pattern using standard globbing.
    #    This handles:
    #    - Exact filenames (e.g., -e specific_file.txt)
    #    - Wildcard patterns (e.g., -e '*.log', -e 'build/*', -e '**/temp*')
    if [[ "$path" == $pattern ]]; then
       # echo "DEBUG: User excluded '$path' via glob pattern '$pattern'" >&2
       return 0 # 0 means "should ignore"
    fi

    # 2. ADDED CHECK: Check if the path starts with the pattern followed by a '/'.
    #    This specifically handles cases where the user provides a directory
    #    name without a trailing slash or wildcard (e.g., -e mydir, -e src/objects).
    #    It correctly excludes files *inside* that directory.
    #    Example: path="mydir/file.txt", pattern="mydir" -> [[ "mydir/file.txt" == "mydir/"* ]] is true.
    #    Example: path="src/objects/data.json", pattern="src/objects" -> [[ "src/objects/data.json" == "src/objects/"* ]] is true.
    #    This check generally won't misfire for file patterns like "*.log" because paths
    #    won't typically start with "*.log/".
    if [[ "$path" == "$pattern/"* ]]; then
        # echo "DEBUG: User excluded '$path' via directory prefix from pattern '$pattern'" >&2
        return 0 # 0 means "should ignore"
    fi
  done

  # --- Directory Patterns (Hardcoded) ---
  # (Keep your existing hardcoded ignores)
  [[ "$path" == .git/* ]] && return 0
  [[ "$path" == */__pycache__/* ]] && return 0
  [[ "$path" == */node_modules/* ]] && return 0
  [[ "$path" == venv/* ]] && return 0
  [[ "$path" == .venv/* ]] && return 0
  [[ "$path" == env/* ]] && return 0
  [[ "$path" == .env/* ]] && return 0
  [[ "$path" == */database_api/fixtures/* ]] && return 0
  [[ "$path" == */.svelte-kit/* ]] && return 0
  [[ "$path" == */build/* ]] && return 0

  # --- File Patterns (Hardcoded) ---
  # (Keep your existing hardcoded ignores)
  [[ "$path" == poetry.lock ]] || [[ "$path" == */poetry.lock ]] && return 0
  [[ "$path" == package-lock.json ]] || [[ "$path" == */package-lock.json ]] && return 0
  [[ "$path" == yarn.lock ]] || [[ "$path" == */yarn.lock ]] && return 0
  [[ "$path" == .DS_Store ]] || [[ "$path" == */.DS_Store ]] && return 0

  # --- Ignore the output file itself ---
  # (Keep your existing output file ignore logic)
  OUTPUT_FILE_RELATIVE_TO_ROOT=$(realpath --relative-to="$GIT_ROOT" "$OUTPUT_FILE_ABS" 2>/dev/null)
  if [ -n "$OUTPUT_FILE_RELATIVE_TO_ROOT" ] && [[ "$OUTPUT_FILE_RELATIVE_TO_ROOT" != ".."* ]]; then
      [[ "$path" == "$OUTPUT_FILE_RELATIVE_TO_ROOT" ]] && return 0
  elif [[ "$path" == "$OUTPUT_FILE" ]]; then
       # Fallback logic... might need refinement based on exact usage
       # A simple check might be if the basename matches and it's in the original CWD
       # This is less reliable if the output file isn't in the original CWD
       [[ "$(basename "$path")" == "$OUTPUT_FILE" ]] && [[ -f "$path" ]] && [[ "$(dirname "$path")" == "." ]] && [[ "$PWD" == "$GIT_ROOT" ]] && [[ "$(realpath "$GIT_ROOT/$path")" == "$OUTPUT_FILE_ABS" ]] && return 0
  fi


  # --- Special Case Patterns ---
  # (Keep your existing special case ignores)
  if [[ "$path" == *.mp4 && "$path" != "dambuster/tests/data/sample.mp4" ]]; then
    return 0
  fi

  # Not ignored
  return 1 # 1 means "do not ignore"
}

# --- Optional: Enable Globstar ---
# If you want users to be able to use `**` in their patterns (e.g., -e '**/__pycache__/*')
# you might need to enable globstar at the beginning of the script or within the function.
# Add this near the top of the script if needed:
# shopt -s globstar

# --- Main Processing Logic ---
count=0
processed=0
skipped_ignored=0 # Renamed from skipped_explicit
skipped_depth=0 # New counter for depth skips
skipped_binary=0
skipped_missing=0

echo "Processing files in $TARGET_DIR_DISPLAY_NAME..."
if [ "$MAX_DEPTH" -ne -1 ]; then
    echo "Applying maximum depth: $MAX_DEPTH"
fi

if [ ${#EXCLUDE_PATTERNS[@]} -gt 0 ]; then
    echo "Applying ${#EXCLUDE_PATTERNS[@]} exclusion patterns:"
    printf " - %s\n" "${EXCLUDE_PATTERNS[@]}"
fi


# We are already in GIT_ROOT

# Read null-delimited file list for the target directory
# Use '--' to safely handle paths that might start with '-'
# git ls-files lists files relative to the *repository root*
while IFS= read -r -d $'\0' file; do
  ((count++))

  # Show progress
  if ((count % 100 == 0)); then
      echo -n "." >&2 # Write progress to stderr
  fi

  # Check ignores first (path is relative to repo root)
  if should_ignore "$file"; then
    # echo "DEBUG: Ignored: $file" >&2
    ((skipped_ignored++))
    continue
  fi

  # Check if file exists (it might have been deleted or be submodule reference)
  # Path ($file) is relative to current directory (GIT_ROOT)
  if [ ! -f "$file" ]; then
    # echo "DEBUG: Skipped missing/not file: $file" >&2
    ((skipped_missing++))
    continue
  fi
  if [ "$MAX_DEPTH" -ne -1 ]; then
      current_depth=$(calculate_depth "$file" "$TARGET_DIR")
      if [ "$current_depth" -gt "$MAX_DEPTH" ]; then
          # echo "DEBUG: Skipped depth ($current_depth > $MAX_DEPTH): $file" >&2
          ((skipped_depth++))
          continue
      fi
  fi
  # Check if it's likely a text file using MIME type
  # The check is done on the actual file in the filesystem
  BINARY_PATTERN='^application/(octet-stream|pdf|zip|gzip|x-tar|x-bzip2|x-7z-compressed|x-rar-compressed|vnd\.microsoft\.portable-executable)|^image/|^video/|^audio/|^font/'
  if ! file -b --mime-type "$file" | grep -q -E "$BINARY_PATTERN"; then
    # Append file content (use path relative to repo root for header)
    echo "===================================================" >> "$OUTPUT_FILE_ABS"
    echo "FILE: $file" >> "$OUTPUT_FILE_ABS" # Use the path relative to root
    echo "===================================================" >> "$OUTPUT_FILE_ABS"
    # Use cat on the path relative to current directory (GIT_ROOT)
    cat "$file" >> "$OUTPUT_FILE_ABS"
    echo -e "\n\n" >> "$OUTPUT_FILE_ABS"
    ((processed++))
  else
    # echo "DEBUG: Skipped binary/non-text: $file" >&2
    ((skipped_binary++))
  fi

# Use process substitution with git ls-files targeting the specific directory relative to root
# Pass TARGET_DIR_FOR_GIT. Use -- to be safe.
done < <(git ls-files --cached --others --exclude-standard -z -- "$TARGET_DIR_FOR_GIT")


# --- Final Summary ---
echo # New line after dots (on stderr)
echo # New line for clarity

echo "-----------------------------------------"
echo "Codebase dump for $TARGET_DIR_DISPLAY_NAME complete: $OUTPUT_FILE_ABS"
echo "Total size: $(du -h "$OUTPUT_FILE_ABS" | cut -f1)"
echo "-----------------------------------------"
echo "Files considered by git ls-files in target: $count"
echo "Skipped (Ignored by pattern or rule): $skipped_ignored"
echo "Skipped (Non-File/Missing): $skipped_missing"
echo "Skipped (Non-Text/Binary): $skipped_binary"
echo "Skipped (Exceeded max depth $MAX_DEPTH): $skipped_depth" # Added depth skip count
echo "Text files processed: $processed"
echo "-----------------------------------------"

# Verification math check
total_accounted=$((skipped_ignored + skipped_missing + skipped_binary + processed))
if [[ "$total_accounted" -ne "$count" ]]; then
  echo "Warning: File count mismatch ($total_accounted accounted vs $count total listed)" >&2
  echo "         This might happen if files were modified/deleted during script execution." >&2
fi

# Change back to original directory
cd "$ORIGINAL_PWD" || exit 1

exit 0 # Success


===================================================
FILE: .github/workflows/deploy.yaml
===================================================
name: Deploy Infrastructure

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  discover-quadlet:
    runs-on: [self-hosted, quadlet]
    outputs:
      containers: ${{ steps.set-matrix.outputs.containers }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Find container definitions
        id: set-matrix
        run: |
          CONTAINERS=$(find ./containers -name "*.container" -exec basename {} .container \; | jq -R -s -c 'split("\n")[:-1]')
          echo "containers=$CONTAINERS" >> "$GITHUB_OUTPUT"
          echo "Found containers: $CONTAINERS"

  deploy-quadlet:
    runs-on: [self-hosted, quadlet]
    needs: discover-quadlet
    strategy:
      matrix:
        container: ${{ fromJson(needs.discover-quadlet.outputs.containers) }}
      fail-fast: false
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Ensure packages
        run: |
          sudo apt-get update 
          sudo apt-get install -y $(cat ./packages)
        
      - name: Get user ID
        id: get-uid
        run: |
          USER_ID=$(id -u ${{ secrets.SYSTEM_USER }})
          echo "uid=$USER_ID" >> $GITHUB_OUTPUT
      
      - name: Deploy ${{ matrix.container }} container
        env:
          USER_ID: ${{ steps.get-uid.outputs.uid }}
        run: |
          envsubst < "./containers/${{ matrix.container }}.container" | sudo tee "/etc/containers/systemd/${{ matrix.container }}.container"
          
      - name: Reload systemd daemon
        run: |
          sudo systemctl daemon-reload
      
      - name: Pull new images
        run: |
          sudo podman auto-update
          
      - name: Restart ${{ matrix.container }} container
        run: |
          sudo systemctl restart ${{ matrix.container }}.service
      
      - name: Check containers are active
        run: |
          sudo systemctl is-active ${{ matrix.container }}.service
      
      - name: Output list of running containers
        run: | 
          sudo podman ps
        if: success() || failure()

  deploy-k3s:
    runs-on: [self-hosted, k3s]
    env:
      KUBECONFIG: /etc/rancher/k3s/k3s.yaml
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # - name: Install kubectl
      #   run: |
      #     sudo apt-get update
      #     sudo apt-get install -y apt-transport-https ca-certificates curl
      #     curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-archive-keyring.gpg
      #     echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
      #     sudo apt-get update
      #     sudo apt-get install -y kubectl

      # - name: Install Helm
      #   run: |
      #     curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

      # - name: Configure k3s
      #   run: |
      #     # Install k3s if not already installed
      #     if ! command -v k3s &> /dev/null; then
      #       curl -sfL https://get.k3s.io | sh -
      #     fi
          
      #     # Wait for k3s to be ready
      #     timeout 60s bash -c 'until kubectl get nodes; do sleep 2; done'
          
      #     # Get kubeconfig
      #     sudo cat /etc/rancher/k3s/k3s.yaml > $HOME/.kube/config
      #     sudo chown $(id -u):$(id -g) $HOME/.kube/config
      #     chmod 600 $HOME/.kube/config

      - name: Create user ID secret
        run: |
          USER_ID=$(id -u ${{ secrets.SYSTEM_USER }})
          export USER_ID  # Export it so envsubst can access it
          envsubst < "./helm/base-config/user-id-secret.yaml" | kubectl apply -f -

      - name: Install ArgoCD
        run: |
          # Install ArgoCD using our chart
          helm dependency update ./helm/argo-cd
          helm upgrade --install argocd ./helm/argo-cd \
            --namespace argocd \
            --wait

          # Create Git credentials secret
          kubectl apply -f - <<EOF
          apiVersion: v1
          kind: Secret
          metadata:
            name: github-repo
            namespace: argocd
            labels:
              argocd.argoproj.io/secret-type: repository
          stringData:
            url: https://github.com/scrungus/homelab.git
            username: scrungus
            password: ${{ secrets.GH_PAT }}
          EOF
      
      - name: Apply Application CRDs
        run: |
          kubectl apply -f helm/apps/


===================================================
FILE: README.md
===================================================
# homelab



===================================================
FILE: containers/koel/.env
===================================================
APP_NAME=koel
APP_ENV=production
APP_DEBUG=true
APP_URL=http://localhost:8000

# A comma-separated list of (Koel server) hostnames accepted to access Koel.
# Leave this empty to allow access to Koel with any hostname.
# Example: localhost,192.168.0.1,yourdomain.com
TRUSTED_HOSTS=

# A random 32-char string. You can leave this empty if use php artisan koel:init.
APP_KEY=

# Database connection name, which corresponds to the database driver.
# Possible values are:
#   mysql (MySQL/MariaDB - default)
#   pgsql (PostgreSQL)
#   sqlsrv (Microsoft SQL Server)
#   sqlite-persistent (Local sqlite file)
# IMPORTANT: This value must present for `artisan koel:init` command to work.
DB_CONNECTION=mysql

DB_HOST=127.0.0.1
DB_PORT=3306
DB_DATABASE=koel
DB_USERNAME=koel
DB_PASSWORD=testpass

# The storage driver. Valid values are:
# local: Store files on the server's local filesystem.
# sftp: Store files on an SFTP server.
# s3: Store files on Amazon S3 or a S3-compatible service (e.g. Cloudflare R2 or DigitalOcean Spaces). Koel Plus only.
# dropbox: Store files on Dropbox. Koel Plus only.
STORAGE_DRIVER=local

# The streaming method.
# Can be either 'php' (default), 'x-sendfile', or 'x-accel-redirect'
# See https://docs.koel.dev/usage/streaming for more information.
# Note: This setting doesn't have effect if the media needs transcoding (e.g. FLAC).
# ##################################################
# It's HIGHLY recommended to use 'x-sendfile' or 'x-accel-redirect' if
# you plan to use the Koel mobile apps.
# ##################################################
STREAMING_METHOD=php

# Full text search driver.
# Koel supports all drivers supported by Laravel (see https://laravel.com/docs/9.x/scout).
# Available drivers: 'tntsearch' (default), 'database', 'algolia' or 'meilisearch'.
# For Algolia or MeiliSearch, you need to provide the corresponding credentials.
SCOUT_DRIVER=tntsearch

# To transcode FLAC to MP3 and stream it on the fly, make sure the following settings are sane.
# If you don't want to transcode FLAC (i.e. to stream it as-is), set this to false.
TRANSCODE_FLAC=false


# The bit rate of the output mp3 stream. Higher value results in better quality,
# but slower streaming and more bandwidth.
OUTPUT_BIT_RATE=128

# Whether to allow song downloading.
# Note that if you're downloading more than one song, Koel will zip them up
# using PHP's ZipArchive. So if the module isn't available in the current
# environment, such a download will (silently) fail.
ALLOW_DOWNLOAD=true


# Whether to create a backup of a song when deleting it from the filesystem.
BACKUP_ON_DELETE=true

# The variables below are Laravel-specific.
# You can change them if you know what you're doing. Otherwise, just leave them as-is.
BROADCAST_DRIVER=log
CACHE_DRIVER=file
FILESYSTEM_DISK=local
QUEUE_CONNECTION=sync
SESSION_DRIVER=file
SESSION_LIFETIME=120


===================================================
FILE: containers/koel/database.container
===================================================
[Container]
Environment=MYSQL_ROOT_PASSWORD=testpass MYSQL_DATABASE=koel MYSQL_USER=koel MYSQL_PASSWORD=testpass
Image=docker.io/mariadb:10.11
Network=host
Volume=/koeldb:/var/lib/mysql



===================================================
FILE: containers/koel/koel.container
===================================================
[Unit]
Requires=database.service
After=database.service

[Container]
Environment=DB_CONNECTION=mysql DB_HOST=127.0.0.1 DB_USERNAME=koel DB_PASSWORD=testpass DB_DATABASE=koel
Image=docker.io/phanan/koel
Network=host
Volume=/tank/Media/Music:/music
Volume=./.env:/var/www/html/.env
Volume=/tank/Covers/var/www/html/public/img/covers
Volume=/search_index:/var/www/html/storage/search-indexes



===================================================
FILE: containers/node-exporter.container
===================================================
[Container]
Exec='--path.rootfs=/host'
Image=quay.io/prometheus/node-exporter:latest
AutoUpdate=registry
Network=host
PodmanArgs=--pid host
Volume=/:/host:ro,rslave

[Service]
Restart=unless-stopped

[Install]
WantedBy=multi-user.target default.target


===================================================
FILE: containers/vpn.container
===================================================
[Container]
Image=ghcr.io/bubuntux/nordvpn:latest
ContainerName=vpn
AutoUpdate=registry
AddCapability=NET_ADMIN
AddCapability=NET_RAW
Environment=TOKEN=e9f2ab3e2950a608c5456a4a922686066b95004d66e4dbe6b44607f5f9c07b38
# Environment=CONNECT=United_States
Environment=TECHNOLOGY=NordLynx
Environment=NETWORK=192.168.0.0/24
PublishPort=6881:6881
Sysctl=net.ipv6.conf.all.disable_ipv6=1

[Install]
WantedBy=multi-user.target default.target

[Service]
Restart=unless-stopped
Type=notify


===================================================
FILE: helm/apps/argo-cd.yaml
===================================================
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: argocd
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/scrungus/homelab.git
    targetRevision: HEAD
    path: helm/argo-cd
  destination:
    server: https://kubernetes.default.svc
    namespace: argocd
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


===================================================
FILE: helm/apps/cert-manager.yaml
===================================================
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: cert-manager
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/scrungus/homelab.git
    targetRevision: HEAD
    path: helm/cert-manager
  destination:
    server: https://kubernetes.default.svc
    namespace: cert-manager
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true


===================================================
FILE: helm/apps/coredns-config.yaml
===================================================
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: coredns-config
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/scrungus/homelab.git
    targetRevision: HEAD
    path: helm/coredns-config
  destination:
    server: https://kubernetes.default.svc
    namespace: kube-system
  syncPolicy:
    automated:
      prune: true
      selfHeal: true


===================================================
FILE: helm/apps/kube-prometheus-stack-crds.yaml
===================================================
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-prometheus-stack-crds
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "2"
spec:
  project: default
  source:
    repoURL: https://github.com/prometheus-community/helm-charts.git
    path: charts/kube-prometheus-stack/charts/crds/crds/
    targetRevision: kube-prometheus-stack-69.2.0
    directory:
      recurse: true
  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring
  syncPolicy:
    syncOptions:
      - CreateNamespace=true
      - Replace=true
    automated:
      prune: true
      selfHeal: true



===================================================
FILE: helm/apps/kube-prometheus-stack.yaml
===================================================
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-prometheus-stack
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "3"
spec:
  project: default
  source:
    repoURL: https://github.com/scrungus/homelab.git
    targetRevision: HEAD
    path: helm/kube-prometheus-stack
    helm:
      skipCrds: true
  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - Replace=true
      # Prune Last (i.e. after it was synced) to not removed dynamically created admissions/patch jobs/pods
      - PruneLast=true


===================================================
FILE: helm/apps/plex.yaml
===================================================
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: plex
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/scrungus/homelab.git
    targetRevision: HEAD
    path: helm/plex
  destination:
    server: https://kubernetes.default.svc
    namespace: plex
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


===================================================
FILE: helm/apps/qbittorrent.yaml
===================================================
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: qbittorrent
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/scrungus/homelab.git
    targetRevision: HEAD
    path: helm/qbittorrent
  destination:
    server: https://kubernetes.default.svc
    namespace: qbittorrent
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


===================================================
FILE: helm/apps/reflector.yaml
===================================================
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: reflector
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://emberstack.github.io/helm-charts
    chart: reflector
    targetRevision: '*'
  destination:
    server: https://kubernetes.default.svc
    namespace: kube-system
  syncPolicy:
    automated:
      prune: true
      selfHeal: true


===================================================
FILE: helm/apps/registry.yaml
===================================================
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: registry
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/scrungus/homelab.git
    targetRevision: HEAD
    path: helm/registry
  destination:
    server: https://kubernetes.default.svc
    namespace: registry
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


===================================================
FILE: helm/apps/traefik.yaml
===================================================
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: traefik
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/scrungus/homelab.git
    targetRevision: HEAD
    path: helm/traefik
    helm:
      valueFiles:
        - values.yaml
  destination:
    server: https://kubernetes.default.svc
    namespace: kube-system
  syncPolicy:
    automated:
      prune: true
      selfHeal: true


===================================================
FILE: helm/argo-cd/Chart.yaml
===================================================
apiVersion: v2
name: argo-cd
description: ArgoCD Helm chart for homelab
version: 1.0.0
dependencies:
  - name: argo-cd
    version: 7.7.17 # v2.13.3
    repository: https://argoproj.github.io/argo-helm


===================================================
FILE: helm/argo-cd/values.yaml
===================================================
argo-cd:
  server:
    service:
      type: NodePort
      nodePortHttp: 30080
    config:
      repositories: |
        - type: git
          url: https://github.com/scrungus/homelab.git
      url: https://argocd.lab 
    certificate:
      enabled: false  # Disable ArgoCD's certificate management
    ingress:
      enabled: true
      ingressClassName: traefik
      pathType: Prefix
      hostname: argocd.lab
      tls: true
  dex:
    enabled: false
  notifications:
    enabled: false


===================================================
FILE: helm/base-config/user-id-secret.yaml
===================================================
apiVersion: v1
kind: Secret
metadata:
  name: user-id-secret
  namespace: default
  annotations:
    reflector.v1.k8s.emberstack.com/reflection-allowed: "true"
    reflector.v1.k8s.emberstack.com/reflection-auto-enabled: "true"
    reflector.v1.k8s.emberstack.com/reflection-auto-namespaces: ""
type: Opaque
stringData:
  USER_ID: "${USER_ID}"


===================================================
FILE: helm/cert-manager/Chart.yaml
===================================================
apiVersion: v2
name: cert-manager-config
version: 1.0.0
dependencies:
  - name: cert-manager
    version: 1.16.3
    repository: https://charts.jetstack.io


===================================================
FILE: helm/cert-manager/templates/certificates/argo-cd.yaml
===================================================
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: argocd-cert
  namespace: argocd
spec:
  secretName: argocd-server-tls
  duration: 8760h 
  renewBefore: 720h 
  dnsNames:
    - argocd.lab
  usages:
    - server auth
    - client auth
  issuerRef:
    name: homelab-issuer
    kind: ClusterIssuer
    group: cert-manager.io


===================================================
FILE: helm/cert-manager/templates/certificates/plex.yaml
===================================================
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: plex-cert
  namespace: plex
spec:
  secretName: plex-tls
  duration: 8760h
  renewBefore: 720h
  dnsNames:
    - plex.lab
  usages:
    - server auth
    - client auth
  issuerRef:
    name: homelab-issuer
    kind: ClusterIssuer
    group: cert-manager.io


===================================================
FILE: helm/cert-manager/templates/certificates/qbittorrent.yaml
===================================================
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: qbittorrent-cert
  namespace: qbittorrent
spec:
  secretName: qbittorrent-tls
  duration: 8760h 
  renewBefore: 720h 
  dnsNames:
    - qbittorrent.lab
  usages:
    - server auth
    - client auth
  issuerRef:
    name: homelab-issuer
    kind: ClusterIssuer
    group: cert-manager.io


===================================================
FILE: helm/cert-manager/templates/certificates/registry.yaml
===================================================
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: registry-cert
  namespace: registry
spec:
  secretName: registry-tls
  duration: 8760h
  renewBefore: 720h
  dnsNames:
    - registry.lab
  usages:
    - server auth
    - client auth
  issuerRef:
    name: homelab-issuer
    kind: ClusterIssuer
    group: cert-manager.io


===================================================
FILE: helm/cert-manager/templates/certificates/root-ca.yaml
===================================================
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: homelab-root-cert
  namespace: cert-manager
spec:
  isCA: true
  commonName: "Homelab Root CA"
  secretName: homelab-root-cert
  privateKey:
    algorithm: ECDSA
    size: 256
  issuerRef:
    name: homelab-root-issuer
    kind: ClusterIssuer
    group: cert-manager.io


===================================================
FILE: helm/cert-manager/templates/issuers/cluster-issuer.yaml
===================================================
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: homelab-issuer
spec:
  ca:
    secretName: homelab-root-cert


===================================================
FILE: helm/cert-manager/templates/issuers/root-issuer.yaml
===================================================
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: homelab-root-issuer
spec:
  selfSigned: {}


===================================================
FILE: helm/cert-manager/values.yaml
===================================================
cert-manager:
  installCRDs: true
  replicaCount: 1
  prometheus:
    enabled: true


===================================================
FILE: helm/coredns-config/Chart.yaml
===================================================
apiVersion: v2
name: coredns-config
version: 1.0.0


===================================================
FILE: helm/coredns-config/templates/configmap.yaml
===================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns-custom
  namespace: kube-system
data:
  lab.server: |
    lab {
      hosts {
        100.66.242.14 argocd.lab
        100.66.242.14 qbittorrent.lab
        100.66.242.14 grafana.lab
        100.66.242.14 prometheus.lab
        100.66.242.14 alertmanager.lab
        100.66.242.14 plex.lab
        100.66.242.14 registry.lab
        fallthrough
      }
      forward . 8.8.8.8
      log
      errors
    }


===================================================
FILE: helm/coredns-config/templates/service.yaml
===================================================
apiVersion: v1
kind: Service
metadata:
  name: coredns-custom
spec:
  type: NodePort
  ports:
    - name: dns
      port: 53
      targetPort: 53
      protocol: UDP
      nodePort: 32053
    - name: dns-tcp
      port: 53
      targetPort: 53
      protocol: TCP
      nodePort: 32053
  selector:
    k8s-app: kube-dns


===================================================
FILE: helm/kube-prometheus-stack/Chart.yaml
===================================================
apiVersion: v2
name: kube-prometheus-stack
description: A Helm chart for kube-prometheus-stack
type: application
version: 0.1.0
dependencies:
  - name: kube-prometheus-stack
    version: 69.1.2
    repository: https://prometheus-community.github.io/helm-charts


===================================================
FILE: helm/kube-prometheus-stack/values.yaml
===================================================
kube-prometheus-stack:
  crds:
    enabled: false

  prometheusOperator:
    admissionWebhooks:
      certManager:
        enabled: true
      patch:
        enabled: false

  grafana:
    persistence:
      enabled: true
      size: 10Gi
    ingress:
      enabled: true
      ingressClassName: traefik
      annotations:
        cert-manager.io/cluster-issuer: homelab-issuer
      hosts:
        - grafana.lab
      tls:
        - secretName: grafana-tls
          hosts:
            - grafana.lab
    
  prometheus:
    prometheusSpec:
      retention: 30d
      storageSpec:
        volumeClaimTemplate:
          spec:
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 50Gi
    ingress:
      enabled: true
      ingressClassName: traefik
      annotations:
        cert-manager.io/cluster-issuer: homelab-issuer
      hosts:
        - prometheus.lab
      tls:
        - secretName: prometheus-tls
          hosts:
            - prometheus.lab

  alertmanager:
    alertmanagerSpec:
      storage:
        volumeClaimTemplate:
          spec:
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 10Gi
    ingress:
      enabled: true
      ingressClassName: traefik
      annotations:
        cert-manager.io/cluster-issuer: homelab-issuer
      hosts:
        - alertmanager.lab
      tls:
        - secretName: alertmanager-tls
          hosts:
            - alertmanager.lab


===================================================
FILE: helm/plex/Chart.yaml
===================================================
apiVersion: v2
name: plex
description: A Helm chart for Plex Media Server
version: 0.1.0
appVersion: "latest"


===================================================
FILE: helm/plex/templates/NOTES.txt
===================================================
SHITS WORKING BABY!! {{ .Chart.Name }} installed.

Your Plex Media Server has been deployed with the following configuration:
  * Using host network mode
  * Config directory: {{ .Values.persistence.config.path }}
  * Media directories mounted from {{ dir .Values.persistence.media.movies.path }}

To access your Plex server:
1. Wait for the pod to be ready:
   kubectl get pods --namespace {{ .Release.Namespace }} -l "app=plex"

2. Since the server is running in host network mode, you can access it directly:
   * Web Interface: http://<node-ip>:32400/web


===================================================
FILE: helm/plex/templates/deployment.yaml
===================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-plex
spec:
  replicas: 1
  selector:
    matchLabels:
      app: plex
  template:
    metadata:
      labels:
        app: plex
    spec:
      containers:
        - name: plex
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - containerPort: 32400
              protocol: TCP
          env:
            - name: PUID
              valueFrom:
                secretKeyRef:
                  name: user-id-secret
                  key: USER_ID
            - name: PGID
              valueFrom:
                secretKeyRef:
                  name: user-id-secret
                  key: USER_ID
            - name: TZ
              value: {{ .Values.environment.TZ | quote }}
            - name: VERSION
              value: {{ .Values.environment.VERSION | quote }}
          readinessProbe:
            httpGet:
              path: /identity
              port: {{ .Values.service.port }}
            initialDelaySeconds: 15
            timeoutSeconds: 5
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /identity
              port: {{ .Values.service.port }}
            periodSeconds: 25
            initialDelaySeconds: 10
            timeoutSeconds: 10
          volumeMounts:
            - name: config
              mountPath: /config
            - name: anime
              mountPath: /media/Anime
            - name: animefilms
              mountPath: /media/AnimeFilms
            - name: homemedia
              mountPath: /media/HomeMedia
            - name: movies
              mountPath: /media/Movies
            - name: music
              mountPath: /media/Music
            - name: shortfilms
              mountPath: /media/ShortFilms
            - name: tvseries
              mountPath: /media/TVSeries
            - name: documentaries
              mountPath: /media/Documentaries
      volumes:
        - name: config
          persistentVolumeClaim:
            claimName: plex-config
        - name: anime
          hostPath:
            path: {{ .Values.persistence.media.anime.path }}
        - name: animefilms
          hostPath:
            path: {{ .Values.persistence.media.animeFilms.path }}
        - name: homemedia
          hostPath:
            path: {{ .Values.persistence.media.homeMedia.path }}
        - name: movies
          hostPath:
            path: {{ .Values.persistence.media.movies.path }}
        - name: music
          hostPath:
            path: {{ .Values.persistence.media.music.path }}
        - name: shortfilms
          hostPath:
            path: {{ .Values.persistence.media.shortFilms.path }}
        - name: tvseries
          hostPath:
            path: {{ .Values.persistence.media.tvSeries.path }}
        - name: documentaries
          hostPath:
            path: {{ .Values.persistence.media.documentaries.path }}


===================================================
FILE: helm/plex/templates/ingress.yaml
===================================================
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: plex
  namespace: plex
  annotations:
    kubernetes.io/ingress.provider: traefik
spec:
  ingressClassName: traefik
  tls:
    - hosts:
        - plex.lab
      secretName: plex-tls
  rules:
    - host: plex.lab
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: plex-plex
                port:
                  number: {{ .Values.service.port }}


===================================================
FILE: helm/plex/templates/pv.yaml
===================================================
apiVersion: v1
kind: PersistentVolume
metadata:
  name: plex-config
spec:
  capacity:
    storage: 100Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /appdata/plex
  storageClassName: local-path
  claimRef:
    namespace: plex
    name: plex-config


===================================================
FILE: helm/plex/templates/pvc.yaml
===================================================
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: plex-config
  namespace: plex
spec:
  volumeName: plex-config
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: local-path


===================================================
FILE: helm/plex/templates/service.yaml
===================================================
apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}-plex
spec:
  type: {{ .Values.service.type }}
  ports:
    - port: {{ .Values.service.port }}
      targetPort: 32400
      nodePort: {{ .Values.service.nodePort }}
      protocol: TCP
      name: http
  selector:
    app: plex


===================================================
FILE: helm/plex/values.yaml
===================================================
# Default values for Plex
image:
  repository: lscr.io/linuxserver/plex
  tag: latest
  pullPolicy: Always

# Service configuration
service:
  type: NodePort
  port: 32400
  nodePort: 32400

# Environment configuration
environment:
  TZ: Etc/UTC
  VERSION: docker

# Storage configuration
persistence:
  config:
    path: /appdata/plex
  media:
    anime:
      path: /tank/Media/Anime
    animeFilms:
      path: /tank/Media/AnimeFilms
    homeMedia:
      path: /tank/Media/HomeMedia
    movies:
      path: /tank/Media/Movies
    music:
      path: /tank/Media/Music
    shortFilms:
      path: /tank/Media/ShortFilms
    tvSeries:
      path: /tank/Media/TVSeries
    documentaries:
      path: /tank/Media/Documentaries


===================================================
FILE: helm/qbittorrent/Chart.yaml
===================================================
apiVersion: v2
name: qbittorrent
version: 1.0.0


===================================================
FILE: helm/qbittorrent/templates/deployment.yaml
===================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: qbittorrent
spec:
  replicas: 1
  selector:
    matchLabels:
      app: qbittorrent
  template:
    metadata:
      labels:
        app: qbittorrent
    spec:
      containers:
      - name: qbittorrent
        image: lscr.io/linuxserver/qbittorrent:latest
        env:
          - name: PUID
            valueFrom:
              secretKeyRef:
                name: user-id-secret
                key: USER_ID
          - name: PGID
            valueFrom:
              secretKeyRef:
                name: user-id-secret
                key: USER_ID
          - name: TZ
            value: "Etc/UTC"
          - name: WEBUI_PORT
            value: "8080"
          - name: TORRENTING_PORT
            value: "6881"
        ports:
        - containerPort: 8080
          name: webui
        - containerPort: 6881
          name: torrenting
          protocol: TCP
        volumeMounts:
        - name: config
          mountPath: /config
        - name: downloads
          mountPath: /downloads
      volumes:
      - name: config
        persistentVolumeClaim:
          claimName: qbittorrent-config
      - name: downloads
        persistentVolumeClaim:
          claimName: qbittorrent-downloads


===================================================
FILE: helm/qbittorrent/templates/ingress.yaml
===================================================
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: qbittorrent
  annotations:
    kubernetes.io/ingress.class: traefik
    kubernetes.io/ingress.provider: traefik
spec:
  ingressClassName: traefik
  tls:
    - hosts:
        - qbittorrent.lab
      secretName: qbittorrent-tls
  rules:
    - host: qbittorrent.lab
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: qbittorrent
                port:
                  number: 8080


===================================================
FILE: helm/qbittorrent/templates/pv.yaml
===================================================
apiVersion: v1
kind: PersistentVolume
metadata:
  name: qbittorrent-config
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /appdata/qbittorrent
  storageClassName: local-path
  claimRef:
    namespace: qbittorrent
    name: qbittorrent-config
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: qbittorrent-downloads
spec:
  capacity:
    storage: 500Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /tank/torrents
  storageClassName: local-path
  claimRef:
    namespace: qbittorrent
    name: qbittorrent-downloads


===================================================
FILE: helm/qbittorrent/templates/pvc.yaml
===================================================
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: qbittorrent-downloads
  namespace: qbittorrent
spec:
  volumeName: qbittorrent-downloads
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500Gi
  storageClassName: local-path
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: qbittorrent-config
  namespace: qbittorrent
spec:
  volumeName: qbittorrent-config
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: local-path


===================================================
FILE: helm/qbittorrent/templates/service.yaml
===================================================
apiVersion: v1
kind: Service
metadata:
  name: qbittorrent
spec:
  type: NodePort
  selector:
    app: qbittorrent
  ports:
  - name: webui
    port: 8080
    targetPort: webui
    nodePort: 30088
  - name: torrenting
    port: 6881
    targetPort: torrenting
    protocol: TCP
    nodePort: 30681


===================================================
FILE: helm/qbittorrent/values.yaml
===================================================



===================================================
FILE: helm/registry/Chart.yaml
===================================================
apiVersion: v2
name: registry
description: Docker Registry for local development
version: 0.1.0
appVersion: "2"


===================================================
FILE: helm/registry/templates/deployment.yaml
===================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: registry
spec:
  replicas: 1
  selector:
    matchLabels:
      app: registry
  template:
    metadata:
      labels:
        app: registry
    spec:
      containers:
        - name: registry
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - containerPort: 5000
          volumeMounts:
            - name: storage
              mountPath: {{ .Values.persistence.mountPath }}
      volumes:
        - name: storage
          {{- if .Values.persistence.enabled }}
          persistentVolumeClaim:
            claimName: registry
          {{- else }}
          emptyDir: {}
          {{- end }}


===================================================
FILE: helm/registry/templates/ingress.yaml
===================================================
{{- if .Values.ingress.enabled -}}
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: registry
  annotations:
    kubernetes.io/ingress.provider: traefik
spec:
  ingressClassName: {{ .Values.ingress.className }}
  tls:
    - hosts:
        - {{ .Values.ingress.host }}
      secretName: registry-tls
  rules:
    - host: {{ .Values.ingress.host }}
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: registry
                port:
                  number: {{ .Values.service.port }}
{{- end }}


===================================================
FILE: helm/registry/templates/service.yaml
===================================================
apiVersion: v1
kind: Service
metadata:
  name: registry
spec:
  type: {{ .Values.service.type }}
  ports:
    - port: {{ .Values.service.port }}
      targetPort: 5000
      protocol: TCP
      name: http
  selector:
    app: registry


===================================================
FILE: helm/registry/templates/storage.yaml
===================================================
{{- if .Values.persistence.enabled -}}
apiVersion: v1
kind: PersistentVolume
metadata:
  name: registry
spec:
  capacity:
    storage: {{ .Values.persistence.size }}
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  {{- if .Values.persistence.storageClass }}
  storageClassName: {{ .Values.persistence.storageClass }}
  {{- end }}
  hostPath:
    path: {{ .Values.persistence.hostPath }}
    type: DirectoryOrCreate
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: registry
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: {{ .Values.persistence.size }}
  {{- if .Values.persistence.storageClass }}
  storageClassName: {{ .Values.persistence.storageClass }}
  {{- end }}
{{- end }}


===================================================
FILE: helm/registry/values.yaml
===================================================
image:
  repository: registry
  tag: 2
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 5000

ingress:
  enabled: true
  className: traefik
  host: registry.lab
  tls: true

persistence:
  enabled: true
  storageClass: ""
  size: 20Gi
  mountPath: /var/lib/registry
  hostPath: /mnt/registry-data


===================================================
FILE: helm/traefik/Chart.yaml
===================================================
apiVersion: v2
name: traefik
version: 1.0.0
dependencies:
  - name: traefik
    version: 27.0.0  # Use the version you want
    repository: https://helm.traefik.io/traefik


===================================================
FILE: helm/traefik/values.yaml
===================================================
traefik:
  additionalArguments:
    - "--log.level=DEBUG"
    - "--providers.kubernetesingress.allowexternalnameservices=true"
    - "--providers.kubernetescrd.allowexternalnameservices=true"
    - "--serversTransport.insecureSkipVerify=true"
  ports:
    websecure:
      tls:
        enabled: true
        certResolver: ""
  service:
    type: LoadBalancer
    spec:
      loadBalancerIP: "100.66.242.14" 
  
  providers:
    kubernetesIngress:
      ingressEndpoint:
        publishedService: "kube-system/traefik"



===================================================
FILE: manifests/testManifest.yaml
===================================================
# hook-test.yaml
---
# Create a namespace for our test
apiVersion: v1
kind: Namespace
metadata:
  name: hook-test
---
# Service Account for the hooks
apiVersion: v1
kind: ServiceAccount
metadata:
  name: hook-sa
  namespace: hook-test
  annotations:
    argocd.argoproj.io/hook: PreSync
---
# Role for secret management in hook-test namespace
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: secret-manager
  namespace: hook-test
  annotations:
    argocd.argoproj.io/hook: PreSync
rules:
- apiGroups: [""]
  resources: ["secrets", "configmaps"]
  verbs: ["create", "get", "delete", "list", "patch"]
- apiGroups: ["batch"]
  resources: ["jobs"]
  verbs: ["get", "list"]
---
# Additional Role for tracking execution in default namespace
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: hook-test-tracker
  namespace: default
rules:
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["create", "get", "update", "patch"]
---
# RoleBinding for the hook-test namespace
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: hook-sa-binding
  namespace: hook-test
  annotations:
    argocd.argoproj.io/hook: PreSync
subjects:
- kind: ServiceAccount
  name: hook-sa
  namespace: hook-test
roleRef:
  kind: Role
  name: secret-manager
  apiGroup: rbac.authorization.k8s.io
---
# Additional RoleBinding for the default namespace
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: hook-test-default-binding
  namespace: default
subjects:
- kind: ServiceAccount
  name: hook-sa
  namespace: hook-test
roleRef:
  kind: Role
  name: hook-test-tracker
  apiGroup: rbac.authorization.k8s.io
---
# PreSync hook job
apiVersion: batch/v1
kind: Job
metadata:
  name: presync-hook
  namespace: hook-test
  annotations:
    argocd.argoproj.io/hook: PreSync
spec:
  ttlSecondsAfterFinished: 100
  template:
    spec:
      serviceAccountName: hook-sa
      containers:
      - name: kubectl
        image: bitnami/kubectl:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "Running PreSync hook job..."
          
          # Create a simple ConfigMap to log that this job ran
          TIMESTAMP=$(date +%s)
          JOB_POD_NAME=$(hostname)
          
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: hook-execution-log-${TIMESTAMP}
            namespace: hook-test
          data:
            pod: "${JOB_POD_NAME}"
            timestamp: "${TIMESTAMP}"
            message: "PreSync hook executed"
            phase: "PreSync"
          EOF
          
          # Create the secret for the application
          echo "Creating secret in PreSync phase"
          kubectl create secret generic test-secret \
            --namespace=hook-test \
            --from-literal=username=admin \
            --from-literal=password=t0p-s3cr3t
          echo "Secret creation completed"
          
          echo "PreSync hook job completed successfully!"
      restartPolicy: Never
  backoffLimit: 2
---
# PostDelete hook job - in the default namespace to avoid namespace deletion issues
apiVersion: batch/v1
kind: Job
metadata:
  name: postdelete-hook
  namespace: default  # Important: This job runs in default namespace
  annotations:
    argocd.argoproj.io/hook: PostDelete
spec:
  ttlSecondsAfterFinished: 600  # Longer TTL for inspection
  template:
    spec:
      serviceAccountName: default  # Using default SA in default namespace
      containers:
      - name: kubectl
        image: bitnami/kubectl:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "Running PostDelete hook job..."
          
          # Create a persistent marker in default namespace
          echo "Creating persistent marker in default namespace..."
          kubectl create configmap postdelete-executed \
            --namespace=default \
            --from-literal=time="$(date)" \
            --from-literal=phase="PostDelete" \
            --from-literal=app="hook-test" 
          
          # Optional: If we still need to clean up anything from the other namespace, try that
          # This might fail if the namespace is already gone, which is fine
          kubectl delete secret test-secret -n hook-test 2>/dev/null || true
          
          # Sleep to give time for inspection
          echo "PostDelete phase sleeping for 60 seconds to allow inspection..."
          sleep 60
          echo "Sleep completed"
          
          echo "PostDelete hook job completed successfully!"
      restartPolicy: Never
  backoffLimit: 2
---
# A simple deployment that uses the secret
apiVersion: apps/v1
kind: Deployment
metadata:
  name: test-app
  namespace: hook-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: test-app
  template:
    metadata:
      labels:
        app: test-app
    spec:
      containers:
      - name: app
        image: nginx:latest
        env:
        - name: USERNAME
          valueFrom:
            secretKeyRef:
              name: test-secret
              key: username
        - name: PASSWORD
          valueFrom:
            secretKeyRef:
              name: test-secret
              key: password


===================================================
FILE: packages
===================================================
podman


